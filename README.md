# 4DOF-ppo-robot-tracking
Master's thesis project: PPO-based control of 4DOF robot in PyBullet to track a target cube.
# ğŸ¤– 4DOF PPO Cube Tracking â€” Master's Thesis

This project presents a reinforcement learning approach using **Proximal Policy Optimization (PPO)** to control a **custom 4-DOF  robotic arm** for **real-time cube tracking** in the **PyBullet** simulation environment. The robot model was exported from **SolidWorks** and integrated into a learning framework for robotic control using PPO.

> ğŸ“ Master's Thesis â€“ Vrije Universiteit Brussel (VUB) & UniversitÃ© libre de Bruxelles (ULB)  
> ğŸ‘¨â€ğŸ”¬ Author: Mayur Ashok Sonawane  
> ğŸ—“ï¸ Academic Year: 2023â€“2024  

---

## ğŸ¯ Project Objectives

- Develop a simulation environment for a 4-DOF robot using URDF in PyBullet.
- Use Proximal Policy Optimization (PPO) for continuous control of the robot.
- Train the robot to track the position of a moving cube.
- Evaluate training performance using reward curves and visual results.
- Create a modular base for future work in robotics, control, and sim-to-real transfer.

---

## ğŸ§  Technical Overview

- **Environment**: PyBullet  
- **Robot Model**: custom 4-DOF version (URDF from SolidWorks)  
- **Algorithm**: PPO (from Stable-Baselines3)  
- **Tracking Goal**: Robot end-effector follows a cube's position  
- **Observation**: Joint positions, velocities, and target cube coordinates  
- **Action Space**: Continuous joint velocity control  
- **Reward**: Distance-based negative reward for tracking accuracy

---

## ğŸ“¸ Demo (Coming Soon)

Videos, GIFs, and screenshots will be uploaded to show robot performance after training.

---

## ğŸ“ Project Directory Structure

4DOF-ppo-robot-tracking/
â”‚
â”œâ”€â”€ urdf/ # Custom 4DOF robot URDF files
â”œâ”€â”€ assets/ # Cube model or mesh files
â”œâ”€â”€ ppo/ # PPO training and evaluation scripts
â”‚ â”œâ”€â”€ train.py # Training loop
â”‚ â”œâ”€â”€ test.py # Evaluate trained agent
â”‚ â””â”€â”€ ppo_agent.py # PPO configuration
â”‚
â”œâ”€â”€ simulation/ # Environment wrapper and robot-cube interaction
â”œâ”€â”€ results/ # Trained models, logs, reward plots
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # Project overview (this file)
---

## âš™ï¸ Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/ur5e-ppo-robot-tracking.git
   cd ur5e-ppo-robot-tracking

2. **Create a Python virtual environment (optional but recommended)**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # or venv\Scripts\activate on Windows
3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt

## ğŸš€ How to Use:

1. **â–¶ï¸ Train the PPO Agent**---
Run the training loop:
   ```bash
   python ppo/train.py

2. **ğŸ® Test the Trained Agent**---
Run the trained policy in simulation:
   ```bash
   python ppo/test.py










