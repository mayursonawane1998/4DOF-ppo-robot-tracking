# 4DOF-ppo-robot-tracking
Master's thesis project: PPO-based control of 4DOF robot in PyBullet to track a target cube.
# ğŸ¤– 4DOF PPO Cube Tracking â€” Master's Thesis

This project presents a reinforcement learning approach using **Proximal Policy Optimization (PPO)** to control a **custom 4-DOF UR5e robotic arm** for **real-time cube tracking** in the **PyBullet** simulation environment. The robot model was exported from **SolidWorks** and integrated into a learning framework for robotic control using PPO.

> ğŸ“ Master's Thesis â€“ Vrije Universiteit Brussel (VUB) & UniversitÃ© libre de Bruxelles (ULB)  
> ğŸ‘¨â€ğŸ”¬ Author: Mayur Ashok Sonawane  
> ğŸ—“ï¸ Academic Year: 2023â€“2024  

---

## ğŸ¯ Project Objectives

- Develop a simulation environment for a 4-DOF UR5e robot using URDF in PyBullet.
- Use Proximal Policy Optimization (PPO) for continuous control of the robot.
- Train the robot to track the position of a moving cube.
- Evaluate training performance using reward curves and visual results.
- Create a modular base for future work in robotics, control, and sim-to-real transfer.

---

## ğŸ§  Technical Overview

- **Environment**: PyBullet  
- **Robot Model**: UR5e â€“ custom 4-DOF version (URDF from SolidWorks)  
- **Algorithm**: PPO (from Stable-Baselines3)  
- **Tracking Goal**: Robot end-effector follows a cube's position  
- **Observation**: Joint positions, velocities, and target cube coordinates  
- **Action Space**: Continuous joint velocity control  
- **Reward**: Distance-based negative reward for tracking accuracy

---

## ğŸ“¸ Demo (Coming Soon)

Videos, GIFs, and screenshots will be uploaded to show robot performance after training.

---

## ğŸ“ Project Directory Structure

